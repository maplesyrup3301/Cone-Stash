# 随机事件与概率
随机试验的每个结果称为**样本点**，而样本点的全体称为**样本空间**
例如，掷一次均匀六面骰的样本空间是：
$$
\Omega=\{1, 2, 3, 4, 5, 6\}
$$
在试验中我们往往只关心某一些样本点——事件；样本空间的子集称为一个**事件**
例如，事件$A$：”掷一次均匀六面骰，得到点数大于3“
$$
A=\{4, 5, 6\}
$$
每次必然发生的事件称为**必然事件**；必然不发生的事件称为**不可能事件**
事件既然是集合，就符合集合之间的关系和运算规律；
1. 事件集合相等的事件是相等事件；
2. 事件集合的并集代表并事件；同理有交事件、差事件；
3. 若$A\cap B=\varnothing$，则事件$A,B$互斥；
4. 若$A\cup B=\Omega, A\cap B=\varnothing$，则$A, B$互为逆事件

重复试验$n$次，事件$A$发生的次数$n_A$称为其频数，比值$n_A/n$称为其**频率**，记作$f_n(A)$
频率的性质有：
1. $f_n(A)\in[0, 1]$
2. $f_n(\Omega)=1$
3. 对于有限个两两互斥事件$A_1, A_2, \dots, A_m$
$$
f_n\left[ \bigcup_{i=1}^m A_i \right]=\sum_{i=1}^mf_n(A_i)
$$

随机事件发生的可能性称为**概率**；<u>注意概率是客观确定的，而频率只是通过反复试验得到的近似</u>
对于事件空间的任意子集$A$，我们为其配属一个数$P(A)$，称为概率；
概率的性质有：
1. $P(A)\in[0, 1]$
2. $P(\Omega)=1$，$P(\varnothing)=0$
3. 对于任意的两两互斥事件$A_1, A_2, \dots, A_m,\dots$
$$
P\left[ \bigcup_{i} A_i \right]=\sum_{i}P(A_i)
$$

注意频率只有有限可加性，而概率不需要”有限“的限制
概率一个重要的性质是**容斥原理**：
对于事件空间中任意一组事件$A_1, A_2,\dots, A_m$：
$$
P\left[ \bigcup_{i=1}^m A_i \right]=
\sum_{i=1}^n
\left[
(-1)^{i-1}\sum_{1\leq j_1\dots j_i\leq n}P(A_{j_1}A_{j_2}\dots A_{j_i})
\right]
$$
特别当$n=2$时：
$$
P(A\cup B)=P(A)+P(B)-P(AB)
$$

**古典概型**是有限等概率的样本空间；对于事件$A$，其概率计算为：
$$
P(A)=\frac{|A|}{|\Omega|}
$$
因为古典概型的离散性，我们常常需要应用组合数学的公式；
（全排列）$n$个不同物体的排列称为全排列，对应的全排列数为$P_n=n!$
（组合）从$n$个物体中不考虑排列地选择$k$个的方法数称为组合数，记为$C_n^k$
$$
C_n^k=\frac{n!}{k!(n-k)!}
$$
（选排列）从$n$个物体中考虑排列地选择$k$个的方法数称为排列数，记为$A_n^k$
$$
A_n^k=\frac{n!}{(n-k)!}=k!\cdot C_n^k
$$
（互异分组）把$n$个不同物体分成$k$组，每组的事物数为$n_i$，则分组方法的种数为：
$$
\frac{n!}{\prod^{k}_{i=1}n_i!}
$$
（放回抽取）从$n$个不同物体中可放回地、不考虑排列地抽取$k$次，所有不同组合的个数为：
$$
\frac{(n+k-1)!}{k!(n-1)!}
$$
例如投四个均匀六面骰一次，则不计排列所有可能的组合种数为：
$$
\frac{(6+4-1)!}{4!(6-1)!}=126
$$

下面给出两个有趣的古典概率问题：
（抽样问题）给定一组$N$个产品，其中次品有$M$个；现从中抽取$n$个，问其中次品个数为$k$个的概率
1. 有放回抽样问题$A$
$$
P(A)=C_n^k\cdot\frac{M^k(N-M)^{n-k}}{N^n}
$$
2. 无放回抽样问题$B$
$$
P(B)=\frac{C_M^k\cdot C_{N-M}^{n-k}}{C_N^n}
$$

（随机配对问题）给不同的$n$个物体编号后随机打乱编号，求至少一人前后编号不变的概率$P(M)$
设事件$M_k$：“有$k$个物体前后编号未变”，则：
$$
P(M_k)=C_n^k\frac{(n-k)!}{n!}=\frac{1}{k!}
$$
由容斥原理得到：
$$
P(M)=P(M_1)-P(M_2)+\dots+(-1)^{n-1}P(M_n)\approx1-e^{-1}=0.632\dots
$$

在一个事件$B$发生前提下另一个事件$A$发生的概率称为**条件概率**，记作$P(A|B)$
$$
P(A|B)=\frac{P(AB)}{P(B)}
$$
（贝叶斯公式）不难发现：
$$
P(A|B)P(B)=P(AB)=P(B|A)P(A)
$$
整理就得到**贝叶斯公式**：
$$
P(A|B)=\frac{P(B|A)P(A)}{P(B)}
$$
（全概率公式）考虑一组两两互斥事件$B_1, B_2,\dots, B_n,\dots$满足$B_1\cup B_2 \dots B_n\dots=\Omega$，则对任意事件$A$有：
$$
P(A)=\sum_{i=1}^\infty P(A|B_i)P(B_i)
$$
这就是**全概率公式**
对贝叶斯公式应用全概率公式得到：
$$
P(B_i|A)=\frac{P(A|B_i)P(B_i)}{\sum^\infty_{j=1}P(A|B_j)P(B_j)}
$$

如果$P(A|B)=P(A)$就说明事件$B$不影响事件$A$，从而有：
$$
P(AB)=P(A)P(B)
$$
称这两个事件是**独立的**；
<u>注意两两独立和相互独立的区别，两两独立不能保证多个事件相互独立</u>
# 随机变量及其分布
通过给每个样本点配属一个数，我们可以把随机事件用更加数学的语言描述；
如果对于样本空间内每一个样本点$\omega$，都配属唯一实数$X(\omega)$与之对应，则称$X=X(\omega)$为**随机变量**；

对于离散型随机变量：设其所有可能取值为$x_k$；令$p_k=P(X=x_k)$，则有：
1. $p_k\geq 0$
2. $\sum_{i=1}^\infty p_k=1$
称$\{p_k\}$为$X$的**分布律**；许多随机变量都服从一些已知的分布

下面是一些重要的分布：
1. $(0-1)$分布
进行一个结果只有两种可能的试验；给其中一种概率为$p$的可能（“成功”）配属$X=1$而另一种可能（“失败”）配属$X=0$，则其样本空间为$\Omega=\{0, 1\}$

| $x_k$ | $P(X=x_k)$ |
| ----- | ---------- |
| $1$   | $p$        |
| $0$   | $1-p$      |

2. 二项分布
重复$n$次成功概率为$p$的服从$(0-1)$分布的试验称为$n$重伯努利试验，令$X$为成功的次数，则其样本空间为$\Omega=\{0, 1, 2, \dots, n\}$
$$
P(X=k)=C_n^kp^k(1-p)^{n-k}
$$
我们记$q=1-p$，则$b(k; n, p)=C_n^kp^kq^{n-k}$，而$B(n, p)=\{b(k;n, p)\}$
随机变量服从二项分布记为：$X\sim B(n, p)$
$$
\alpha = \frac{b(k;n, p)}{b(k-1;n, p)}=1+\frac{(n+1)p-k}{kq}
$$
不难发现在$k=(n+1)p$附近二项分布取到最大值，或是一个值或是两个值；
这个$k$称为二项分布的最可能出现次数，而该项称为中心项；
3. 泊松分布
设$X=1, 2,3\dots$
$$
P(X=k)=\frac{\lambda^ke^{-\lambda}}{k!}, k=1,2,3\dots
$$
泊松分布可以用来近似二项分布；记为$X\sim P(\lambda)$
（泊松定理）设$\lambda>0$是一个常数，$n$为正整数，$\lim_{n\rightarrow\infty}np_n=\lambda$，则对任一非负整数$k$有：
$$
\lim_{n\rightarrow\infty}C_n^kp_n^kq_n^{n-k}=\frac{\lambda^ke^{-\lambda}}{k!}
$$
由于$\lambda=np$，当$n$很大时$p$一定很小；在这种情况下，可以用泊松分布近似二项分布：
$$
C_n^kp_n^kq_n^{n-k}\approx\frac{\lambda^ke^{-\lambda}}{k!}
$$
就泊松分布自身来说，其描述的随机现象有如下三个特性：
1. 平稳性：事件发生的频率不随事件变化，在一段时间内发生的次数仅与时间段长度有关而和开始时间无关
2. 独立性：在不相交的时间段内的发生是独立的
3. 普通性：在很短的时间内发生多次的概率很小而发生一次的概率近似为$\lambda$

对于非离散型随机变量，大多数都落在一个区间内；
设$X\in[a, b]$，称：
$$
F(x)=P(X\leq x),a\leq x\leq b
$$
为随机变量的分布函数
其性质为：
1. $F(x)$非降
2. $F(\infty)=1, F(-\infty)=0$
3. $F(x+)=F(x)$（右连续）

若存在$f(x)$使得：
$$
F(x)=\int_{-\infty}^xf(t)\text d t
$$
则称$X$为连续型随机变量，$f(x)$为其密度函数

下面是一些重要的分布：
1. 均匀分布
随机变量$X\in[a, b]$
密度函数：
$$
f(x)=
\begin{cases}
\frac1{b-a}, a<x<b,\\
0, otherwise.
\end{cases}
$$
分布函数：
$$
F(x)=
\begin{cases}
0, x<a,\\
\frac{x-a}{b-a},a\leq x<b,\\
1, x\geq b
\end{cases}
$$
记为$X\sim U(a, b)$

2. 正态分布
密度函数：
$$
f(x)=\frac1{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$
其中$\mu$称为位置参数，$\sigma$称为刻度参数；记为$X\sim N(\mu, \sigma^2)$
正态分布的存在非常广泛；因为正态分布是二项分布的连续扩展，而许多自然现象可以抽象为许多连续的伯努利试验，因此常常出现在各种领域的各种方面；
当$\mu=0, \sigma=1$时，称其为标准正态分布；密度函数、分布函数特别记为$\varphi(x), \Phi(x)$
$$
\varphi(x)=\frac1{\sqrt{2\pi}}e^{-\frac{x^2}2}, 
\Phi(x)=\frac1{\sqrt{2\pi}}\int_{-\infty}^xe^{-\frac{x^2}2}\text d t
$$
易知$\Phi(-x)=1-\Phi(x)$
对于$X\sim N(\mu, \sigma^2)$，则$Z=\frac{X-\mu}{\sigma}\sim N(0, 1)$
3. 指数分布
密度函数：
$$
f(x)=
\begin{cases}
\lambda e^{-\lambda x}, x\geq 0,\\
0,x<0.
\end{cases}
$$
分布函数：
$$
F(x)=
\begin{cases}
1-e^{-\lambda x}, x\geq 0,\\
0,x<0.
\end{cases}
$$
指数分布常常用来事物的寿命；记为$X\sim Exp(\lambda)$
假设一个受到冲击立刻失效的元件受到冲击的分布是泊松流，则可以推导出其正常工作（不受到冲击）时间服从指数分布；
4. $\Gamma$分布
$\Gamma$分布是指数分布的推广；假设指数分布所描述的元件在失效前可以承受$r$次冲击，假设受到的冲击是一个泊松流，则元件的寿命服从$\Gamma$分布；记为$X\sim\Gamma(r, \lambda)$
密度函数：
$$
f(x)=
\begin{cases}
\frac{\lambda^r}{\Gamma(r)}x^{r-1}e^{-\lambda x}, x\geq 0,\\
0,x<0.
\end{cases}
$$
其中：
$$
\Gamma(r)=\int_0^\infty x^{r-1}e^{-x}\text dx
$$
当$r$为自然数时$\Gamma(r)=(r-1)!$

实际中，我们常常关心**随机变量的函数**，也即知道$y=g(x)$和$X$的分布，求$Y=g(X)$的分布；
离散型随机变量的分布律容易计算，只要依次应用$y=g(x)$即可；我们主要讨论函数作用下的连续型随机变量的分布律
1. $Y=a+bX(b\neq 0)$
$$
f_Y(x)=\frac1{|b|} f(\frac{x-a}{b})
$$
2. $Y=X^2$
$$
f_Y(x)=\frac1{2\sqrt x}[f(\sqrt x)+f(-\sqrt {x})](x>0)
$$
当$x\leq 0$时$f_Y(x)=0$

例：
设$X\sim N(0, 1)$且$Y=X^2$
$$
f_Y(y)=\frac1{\sqrt{2\pi}}y^{-\frac12}e^{-\frac y2}(y>0)
$$
$Y$服从自由度为1的$\chi ^2$分布（卡方分布）；

从上面两个例子可以看出，关键步骤是从$g(X)\leq y$中解出$X$；
对于$g(x)$单调且处处可导的情况：
$$
f_Y(y)=f[h(y)]|h'(y)|(\alpha < y < \beta)
$$
其中$\alpha=\min[g(-\infty), g(\infty)], \beta=\max[g(-\infty), g(\infty)], h(y)=g^{-1}(x)$
对于一般的函数则需要分段处理；

# 多维随机变量及其分布
$X,Y$是定义在$\Omega$上的随机变量，则它们构成的二维向量$(X, Y)$是**二维随机变量**或者**随机向量**；
设$(X, Y)$为二维随机变量，则我们称：
$$
F(x, y)=P(X\leq x, Y\leq y)
$$
为**联合分布函数**，简称分布函数；类似地有密度函数；
密度函数满足：
1. $f(x, y)\geq 0$
2. 
$$
\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}f(x, y)\text dx\text dy=1
$$
如果已知密度函数满足上述条件，则其所定义的必然是一个二维随机变量的分布函数且连续；
此外：
1. 若$f(x, y)$在点处连续， 则：
$$
\frac{\partial^2 F(x, y)}{\partial x\partial y}=f(x, y)
$$
2. 设$G$为平面上由逐段光滑的曲线构成的闭合图形，则有：
$$
P[(X, Y)\in G]=\iint_Gf(x, y)\text dx\text dy
$$
二维随机变量最重要的是**二维正态分布**的随机变量：
$$
f(x, y)=\frac1{2\pi\sigma_1\sigma_2\sqrt{1-r^2}}\exp
\left\{
-\frac1{2(1-r^2)}
\left[
\frac{(x-\mu_1)^2}{\sigma_1^2}-
2r\frac{(x-\mu_1)(x-\mu_2)}{\sigma_1\sigma_2}+
\frac{(y-\mu-2)^2}{\sigma_2^2}
\right]
\right\}
$$
记为$(X, Y)\sim N(\mu_1, \mu_2, \sigma_1^2, \sigma_2^2, r)$

对于一个联合分布，我们可以定义关于某变量的其**边缘分布**：
$$
F_X(x)=P(X\leq x)
$$
类似地我们也可以定义条件分布，只不过此时我们固定一个事件，得到的是<u>关于另一个事件的分布律</u>，称为**条件分布律**；
离散情况：
$$
P(X=x|Y=y)=\frac{P(X=x, Y=y)}{P(Y=y)}
$$
连续情况：
$$
P(X\leq x|Y=y)=\lim_{\varepsilon\rightarrow 0^+}\frac{P(X\leq x, y-\varepsilon<Y\leq y+\varepsilon)}{P(y-\varepsilon<Y\leq y+\varepsilon)}
$$
或者记为$F_{X|Y}(x|y)$
（连续条件分布律和边缘分布）
$$
F_{X|Y}(x|y)=\int_{-\infty}^x\frac{f(u, y)}{f_Y(y)}\text du,f_{X|Y}(x|y)=\frac{f(u, y)}{f_Y(y)}
$$

如果随机变量$X, Y$**相互独立**，则
$$
F(x, y)=F_X(x)F_Y(y), f(x, y)=f_X(x)f_Y(y)
$$
对于离散型随机变量：
$$
P(X=x, Y=y)=P(X=x)P(Y=y)
$$

若$(X, Y)\sim N(\mu_1, \mu_2, \sigma_1^2, \sigma_2^2, r)$，$X, Y$相互独立当且仅当$r=0$
已知$(X, Y)$的密度为$f(x, y)$，则$X, Y$相互独立当且仅当$f(x, y)$可分离变量，即：
$$
f(x, y)=g(x)h(y)
$$
注意，<u>分离变量不仅仅包括函数式，更包括其定义域</u>；例如下面的密度就不可分离：
$$
f(x, y)=\frac32x, x\in(0, 1), |y|<x
$$
因为$|y|<x$的区域是不可分离的；我们引入**示性函数**
$$
I_A(x, y)=
\begin{cases}
1, (x, y)\in A,\\
0, otherwise.
\end{cases}
$$
一个可分离的例子：$I_{\{(x, y)|0\leq x\leq 1, 0\leq y\leq 2\}}=I_{\{x|0\leq x\leq 1\}}I_{\{y|0\leq y\leq 2\}}$
可见可分离的区域都是矩形的；

对于多重随机变量：
若$(X_1,\dots, X_n), (Y_1, \dots, Y_m)$相互独立，则任意的$X$和$Y$都相互独立；
若$h, g$分别是$n, m$元的连续函数，则$h(X_1, \dots, X_n), g(Y_1, \dots, Y_m)$相互独立；

两个随机变量函数的分布：
1. $Z=X+Y$
$$
F_Z(z)=P(X+Y\leq z)=\iint_{x+y\leq z}f(x, y)\text dx\text dy
$$
可以得出：
$$
f_Z(z)=f_X*f_Y(z)
$$
其中，$*$表示卷积；
$$
f_X*f_Y(z)=\int_{-\infty}^{\infty}f_X(x)f_Y(z-x)\text dx
$$

补充：$\beta$函数：
$$
B(a, b)=\int_0^1x^{a-1}(1-x)^{b-1}\text dx
$$
其有性质：
$$
B(a, b)=\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}
$$

可以证明：
	 $X\sim N(0, 1), Y\sim N(0, 1)\Rightarrow (X+Y)\sim N(0, 2)$
	 $X\sim \Gamma(r_1, \lambda), Y\sim \Gamma(r_2, \lambda)\Rightarrow (X+Y)\sim \Gamma(r_1+r_2, \lambda)$
	 $X\sim P(\lambda_1), Y\sim P(\lambda_2)\Rightarrow (X+Y)\sim P(\lambda_1+\lambda_2)$

2. $Z=X/Y(Y\neq 0)$
$$
F_Z(z)=P(\frac XY\leq z)=\iint_{\frac xy\leq z}f(x, y)\text dx\text dy
$$
易得：
$$
f_Z(z)=\int_{-\infty}^{\infty}f(yz,y)|y|\text dy
$$

自由度为$n$的$\chi^2$分布就是$\Gamma(n/2, 1/2)$分布；$n$个独立的自由度为1的$\chi^2$分布之和为自由度为$n$的$\chi^2$分布

3. 随机变量最值的分布
已知$M=\max(X, Y), N=\min(X, Y)$，则：
$$
F_M(z)=F_X(z)F_Y(z), F_N(z)=1-[1-F_X(z)][1-F_Y(z)]
$$
可以用来描述串并联系统的特征；

4. 随机变量变换的分布
已知$(\xi_1, \xi_2)$的联合分布为$p(x_1, x_2)$，且：
$$
\begin{cases}
\eta_1=f_1(\xi_1, \xi_2)\\
\eta_2=f_2(\xi_1, \xi_2)\\
\end{cases}
$$
其中$f_1, f_2$有唯一的反函数$f_1^{-1}, f_2^{-1}$，则$(\eta_1, \eta_2)$的联合分布为
$$
g(y_1, y_2)=p[f_1^{-1}(y_1, y_2), f_2^{-1}(y_1, y_2)]|J|
$$
其中$J$为坐标变换的雅可比行列式；
# 随机变量的数字特征及与特征函数
（数学期望）设离散型随机变量$X$的分布律为：
$$
P(X=x_k)=p_k, k=1, 2,\dots
$$
则其**数学期望**为：
$$
E(X)=\sum_{i=1}^\infty x_ip_i
$$
如果$X$是连续型随机变量，则：
$$
E(X)=\int_{-\infty}^\infty xf(x)\text dx
$$
上述数学期望存在的前提是求和或积分**绝对收敛**
若$Y=g(X)$，则：
$$
E(Y)=E[g(X)]
$$
数学期望有如下性质：
1. $E(C)=C(C为常数)$
2. $E(CX)=CE(X)$
3. 对于两个随机变量$X,Y$，有$E(X+Y)=E(X)+E(Y)$
4. 对于两个独立的随机变量$X, Y$，有$E(XY)=E(X)E(Y)$

（方差）设$X$为随机变量，若$E[X-E(X)]^2$存在，则称为$X$的**方差**，记为$D(X)$
并称$\sigma(X)=\sqrt{D(X)}$为**标准差**；
方差有如下性质：
1. $D(X)=0\Leftrightarrow P(X=C)=1$
2. $D(CX)=C^2D(X)$
3. $D(X)=E(X^2)-[E(X)]^2$
4. $D(X+Y)=D(X)+D(Y)$

下面介绍几种分布的数学期望与方差：
1. $(0-1)$分布
$$
E(X)=p, D(X)=p(1-p)
$$
2. 二项分布$X\sim B(n, p)$
$$
E(X)=np, D(X)=npq
$$
3. 泊松分布$X\sim P(\lambda)$
$$
E(X)=D(X)=\lambda
$$
4. 均匀分布$X\sim U(a, b)$
$$
E(X)=\frac{a+b}2, D(X)=\frac{(b-a)^2}{12}
$$
5. 正态分布$X\sim N(\mu, \sigma^2)$
$$
E(X)=\mu, D(X)=\sigma^2
$$
（$3\sigma$原则）
$P(|X-\mu|\leq\sigma)=0.6826$
$P(|X-\mu|\leq 2\sigma)=0.9544$
$P(|X-\mu|\leq 3\sigma)=0.9974$

（切比雪夫不等式）设随机变量$X$的数学期望$E(X)=\mu$，方差$D(X)=\sigma^2$，则对于任意$\varepsilon>0$有：
$$
P(|X-\mu|\geq\varepsilon)\leq\frac{\sigma^2}{\varepsilon^2}
$$
从而：
$$
P(|X-\mu|<\varepsilon)\geq1-\frac{\sigma^2}{\varepsilon^2}
$$
（柯西-施瓦茨不等式）对任意随机变量$X, Y$都有：
$$
[E(XY)]^2\leq E(X^2)E(Y^2)
$$
等式的成立条件是存在$c$使得$P(Y=cX)=1$

（协方差与相关系数）
设$X, Y$是两个随机变量，称
$$
Cov(X, Y)=E\{[X-E(X)][Y-E(Y)]\}
$$
为二者的**协方差**；而
$$
\rho(X, Y)=\frac{Cov(X, Y)}{\sigma(X)\sigma(Y)}
$$
为二者的**相关系数**；
容易证明：
$$
D(X+Y)=D(X)+D(Y)+2Cov(X, Y)
$$
直接展开协方差得到：
$$
Cov(X, Y)=E(XY)-E(X)E(Y)
$$
协方差有如下性质：
1. $Cov(X, Y)=Cov(Y, X)$
2. $Cov(aX, bY)=ab\cdot Cov(X, Y)$
3. $Cov(X+Y, Z)=Cov(X, Z)+Cov(Y, Z)$
相关系数有如下性质：
1. $|\rho(X, Y)|\leq 1$
2. $|\rho(X, Y)|=1\Leftrightarrow \exists a, b\in\mathbb R, P(Y=aX+b)=1$
3. 当$\rho(X, Y)=0$，$X, Y$不<u>线性</u>相关

（矩）设$X, Y$为随机变量
$$
\alpha_k=E(X^k), k=1, 2,\dots
$$
称为$X$的$k$**阶原点矩**，简称$k$阶矩；
$$
\nu_k=E[X-E(X)]^k, k=2, 3,\dots
$$
称为$X$的$k$**阶中心矩**
$$
E(X^lY^k), k,l=2, 3,\dots
$$
称为$X, Y$的$k+l$**阶混合矩**
$$
c_{kl}=E\{[X-E(X)]^k[Y-E(Y)]^l\}, k,l=1, 2,\dots
$$
称为$X, Y$的$k+l$**阶混合中心矩**
显然，数学期望是一阶原点矩，方差是二阶中心矩，协方差是二阶混合中心矩

（$n$维随机向量的协方差矩阵）已知$n$维的随机向量$(X_1, X_2,\dots, X_n)^T$
$$
C=(c_{ij})_{n\times n};c_{ij}=Cov(X_i, X_j)
$$
称为其**协方差矩阵**；它是非负定矩阵；特别的，如果$(X_1, X_2)$服从二维正态分布，则：
$$
C=
\begin{bmatrix}
\sigma_1^2 & r\sigma_1\sigma_2 \\
r\sigma_1\sigma_2 & \sigma_2^2 \\
\end{bmatrix};
C^{-1}=
\begin{bmatrix}
\sigma_2^2 & -r\sigma_1\sigma_2 \\
-r\sigma_1\sigma_2 & \sigma_1^2 \\
\end{bmatrix}
$$
已知$\boldsymbol X=(X_1, X_2, \dots, X_n)^T$；
令$\boldsymbol x=(x_1, x_2, \dots, x_n)^T$，$\boldsymbol \mu=(\mu_1, \mu_2, \dots, \mu_n)^T$
$n$维正态分布的密度函数可以写为：
$$
f(\boldsymbol x)=\frac1{(2\pi)^{n/2}|C|^{1/2}}\exp
\left\{
-\frac12 (\boldsymbol x-\boldsymbol \mu)^TC^{-1}(\boldsymbol x-\boldsymbol \mu)
\right\}
$$

（特征函数\*）给定随机变量$X$，其**特征函数**为$\phi(t)=E(e^{itX})$
分布函数由其特征函数唯一确定；下面给出一些重要的特征函数：
1. 退化分布$P(X=C)=1$
$$
\phi(t)=e^{itC}
$$
2. 二项分布$X\sim B(n, p)$
$$
\phi(t)=(pe^{it}+q)^n
$$
3. 泊松分布$X\sim P(\lambda)$
$$
\phi(t)=\exp[\lambda(e^{it}-1)]
$$
4. 均匀分布$X\sim U(a, b)$
$$
\phi(t)=\frac{e^{itb}-e^{ita}}{it(b-a)}
$$
5. 正态分布$X\sim N(\mu, \sigma^2)$
$$
\phi(t)=e^{i\mu t-\frac12\sigma^2t^2}
$$
6. 指数分布$X\sim Exp(\lambda)(\lambda>0)$
$$
\phi(t)=\left[1-\frac{it}{\lambda}\right]^{-1}
$$
7. $\Gamma$分布$X\sim \Gamma(r, \lambda)$
$$
\phi(t)=\left[1-\frac{it}{\lambda}\right]^{-r}
$$
8. $\chi^2$分布$X\sim\chi^2(n)$
由于$\chi^2(n)$即为$\Gamma(n/2, 1/2)$，有：
$$
\phi(t)=(1-2it)^{-n/2}
$$

特征函数的性质：
1. $\phi(0)=1$
2. $|\phi(t)|\leq \phi(0)$
3. $\phi(-t)=\overline{\phi(t)}$
4. 设$Y=aX+b$，则$\phi_Y(t)=e^{ibt}\phi_X(at)$

设随机变量$X$的$n$阶矩存在，则它的特征函数可微分$n$次，且对$k\leq n$有：
$$
\phi^{(k)}(0)=i^kE(X^k)
$$
两个相互独立的随机变量之和的特征函数为两随机变量特征函数之积；
下面简单介绍$n$维随机向量的特征函数；
$$
\phi(\boldsymbol t)=E(e^{i\boldsymbol t^T\boldsymbol X})
$$
特别当$\boldsymbol X\sim N(\boldsymbol a, C)$时，特征函数为：
$$
\phi(\boldsymbol t)=\exp\left[{i\boldsymbol a^T\boldsymbol t-\frac12\boldsymbol t^TC\boldsymbol t}\right]
$$
随机变量分量相互独立的充要条件是：
$$
\phi(t_1, t_2,\dots, t_n)=\prod_{j=1}^n\phi_{X_j}(t_j)
$$
对于$n$维正态随机变量，各个分量相互独立和不相关是等价的；
$n$维随机变量服从正态分布的充要条件是所有分量的任意线性组合服从一位正态分布；
设$\boldsymbol X^T$服从$n$维正态分布$N(\boldsymbol a, C)$，而$L$为$n\times m$矩阵，则$\boldsymbol Y=L^T\boldsymbol X$服从正态分布$N(L^T\boldsymbol a, L^TCL)$；

已知$U$是$C$的对角化矩阵，即$U^TCU=D$；代入上述定理得到：
$$
\boldsymbol Y\sim N(U^T\boldsymbol a, D)
$$
这表明一个$n$维正态分布随机向量可化为具有独立分量的$n$维正态分布随机向量

设有一系列随机变量$\{X_n\}$，对于的分布函数列为$\{F_n(x)\}$；已知随机变量$X$的分布函数为$F(x)$，如果对于每个连续点都有：
$$
\lim_{n\rightarrow\infty}F_n(x)=F(x)
$$
称分布函数列（弱）收敛于$F(x)$，$X_n$依分布收敛于$X$，记为：
$$
F_n(x)\stackrel{w}{\rightarrow}F(x), X_n\stackrel{L}{\rightarrow}X
$$
可以证明：
（正极限定理）若分布函数列（弱）收敛于$F(x)$，则对应的特征函数列也收敛于$F(x)$的特征函数
（逆极限定理）若特征函数列收敛于特征函数$\phi(t)$，且$\phi(t)$在$t=0$处连续，则相应的分布函数收敛于$F(x)$，且$\phi(t)$是$F(x)$的特征函数
# 大数定律与中心极限定理
设一系列随机变量$X_1, X_2,\dots$，若对任意$\varepsilon>0$，
$$
\lim_{n\rightarrow\infty}P(|X_n-p|<\varepsilon)=1
$$
则称随机变量列依概率收敛于$p$，记为$X_n\stackrel{P}{\rightarrow}p$
若：
$$
\frac1n\sum_{k=1}^nX_k-\frac1n\sum_{k=1}^nEX_k\stackrel{P}{\rightarrow}0
$$
则称该随机变量列服从**大数定律**；

**方差存在情况的大数定律**
1. 切比雪夫大数定律
设随机变量$X_1, X_2, \dots$两两不相关，每个随机变量的方差有限，且有公共上界：
$$
D(X_i)\leq c, i=1, 2,\dots
$$
则对任意$\varepsilon>0$有：
$$
\lim_{n\rightarrow\infty}P
\left[
\left|
\frac1n\sum_{k=1}^nX_k-\frac1n\sum_{k=1}^nEX_k
\right|\lt\varepsilon
\right]=1
$$
表明在多次重复试验中，随机变量的平均值将趋近于随机变量的数学期望；
2. 伯努利大数定律
设$n_A$是$n$次重复事件中事件$A$发生的次数，$p$为事件$A$在每次事件中发生的概率，则对于任意$\varepsilon>0$有：
$$
\lim_{n\rightarrow\infty}P
\left[
\left|
\frac{n_A}{n}-p
\right|<\varepsilon
\right]=1
$$
表明大量重复实验中频率将趋近于概率；

**独立同分布情况的大数定律**
1. 辛钦大数定律
设$X_1, X_2,\dots$是一列独立同分布的随机变量，且数学期望有限：
$$
a=E(X_k), k=1, 2,\dots
$$
则对任意的$\varepsilon>0$有：
$$
\lim_{n\rightarrow\infty}P
\left[
\left |
\frac 1n\sum_{k=1}^nX_k-a
\right|<\varepsilon
\right]=1
$$
表明在多次重复试验中，随机变量的平均值将趋近于随机变量的数学期望；
切比雪夫大数定律不要求同分布，因此更一般

下面我们介绍概率论中的首席定理——**中心极限定理**
中心极限定理表明：对于独立并同分布的随机变量，即使原始变量本身不是正态分布，标准化样本均值的抽样分布也趋向于标准正态分布；
其数学描述如下：

设随机变量$X_1, X_2,\dots$独立同分布，且具有数学期望和方差：$E(X_k)=a, D(X_k)=\sigma^2\neq0, k=1, 2,\dots$，则随机分布：
$$
Y_n=\frac{\sum\limits_{k=1}^nX_k-E\left[\sum\limits_{k=1}^{n}X_k\right]}{\sqrt{D\left[\sum\limits_{k=1}^nX_k\right]}}
=\frac{\sum\limits_{k=1}^nX_k-na}{\sqrt n \sigma}
$$
的分布函数$F_n(x)$对任意的$x$满足：
$$
\lim_{n\rightarrow\infty}F_n(x)=
\lim_{n\rightarrow\infty}P
\left[
\frac{\sum\limits_{k=1}^{n}X_k-na}{\sqrt n\sigma}\leq x
\right]
=\int_{-\infty}^x\frac1{\sqrt{2\pi}}\exp\left[-\frac{t^2}2\right]\text dt
$$
也即$Y\sim N(0, 1)$，$\sum\limits_{k=1}^nX_k\sim N(na, n\sigma^2)$
（棣莫弗-拉普拉斯定理）已知$Y_n\sim B(n, p)$，则对任意的$x$有
$$
\lim_{n\rightarrow\infty}P\left[\frac{Y_n-np}{\sqrt{np(1-p)}}\leq x\right]=\int_{-\infty}^x\frac1{\sqrt{2\pi}}e^{-\frac{x^2}2}\text dt
$$

例：考虑一个不均匀六面骰，六面点数分别为一至六，对应的概率为：

| $x_k$ | $P(X=x_k)$ |
| ----- | ---------- |
| $1$   | $0.1$      |
| $2$   | $0.3$      |
| $3$   | $0.2$      |
| $4$   | $0.1$      |
| $5$   | $0.2$      |
| $6$   | $0.1$      |

若掷骰子$100$次，令点数和为随机变量$Y$；
$$
E(X)=3.3, D(X)=2.41
$$
利用中心极限定理可知$Y$可以视作服从正态分布：
$$
Y\sim N(330, 241)
$$
